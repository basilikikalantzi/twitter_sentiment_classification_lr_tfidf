{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":92791,"databundleVersionId":11083833,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# English Tweets Sentiment Classifier","metadata":{}},{"cell_type":"markdown","source":"> **Note:**  \n> Code comments throughout this notebook include references to experiments conducted during the development process.  \n> These experiments are discussed and analyzed in detail in the accompanying report.\n","metadata":{}},{"cell_type":"markdown","source":"* **Downloads and Unzips**","metadata":{}},{"cell_type":"code","source":"!pip install nltk\n!pip install wordnet\n!pip install negspacy\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:18:42.733159Z","iopub.execute_input":"2025-03-30T20:18:42.733581Z","iopub.status.idle":"2025-03-30T20:19:07.960481Z","shell.execute_reply.started":"2025-03-30T20:18:42.733548Z","shell.execute_reply":"2025-03-30T20:19:07.959337Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Imports all libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport optuna\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.utils import resample\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport spacy\nfrom negspacy.negation import Negex\nfrom spacy.tokens import Doc\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\nfrom wordcloud import WordCloud\nimport re#Word Frequency\n\nfrom collections import Counter\nimport string\n# from sklearn.preprocessing import StandardScaler\nfrom nltk.tokenize import TweetTokenizer\nfrom textblob import TextBlob\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import learning_curve\nfrom html import unescape \n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import FunctionTransformer\n\nfrom sklearn.base import TransformerMixin, BaseEstimator\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:19:54.181244Z","iopub.execute_input":"2025-03-30T20:19:54.181699Z","iopub.status.idle":"2025-03-30T20:20:04.466983Z","shell.execute_reply.started":"2025-03-30T20:19:54.181662Z","shell.execute_reply":"2025-03-30T20:20:04.465823Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Loads the training, validation  and test datasets**","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/ai-2-deep-learning-for-nlp-homework-1/train_dataset.csv')\ntest_data = pd.read_csv('/kaggle/input/ai-2-deep-learning-for-nlp-homework-1/test_dataset.csv')\nval_data = pd.read_csv('/kaggle/input/ai-2-deep-learning-for-nlp-homework-1/val_dataset.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:20:07.043385Z","iopub.execute_input":"2025-03-30T20:20:07.044052Z","iopub.status.idle":"2025-03-30T20:20:07.814894Z","shell.execute_reply.started":"2025-03-30T20:20:07.044015Z","shell.execute_reply":"2025-03-30T20:20:07.813627Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Performs EDA**","metadata":{}},{"cell_type":"code","source":"print(\"Train Data Head:\\n\", train_data.head())\nprint(\"Validation Data Head:\\n\", val_data.head())\nprint(\"Test Data Head:\\n\", test_data.head())\n\nprint(\"\\nTrain Data Info:\")\nprint(train_data.info())\nprint(\"\\nValidation Data Info:\")\nprint(val_data.info())\nprint(\"\\nTest Data Info:\")\nprint(test_data.info())\n\nprint(\"\\nMissing Values in Train Data:\")\nprint(train_data.isnull().sum())\n\nif train_data['Text'].isnull().sum() > 0:\n    print(\"\\nFilling missing values in 'Text' column with 'No Text'\")\n    train_data['Text'].fillna(\"No Text\", inplace=True)\n\n# For the Label column, fill with the most frequent value (mode)\nif train_data['Label'].isnull().sum() > 0:\n    mode_value = train_data['Label'].mode()[0]\n    print(f\"\\nFilling missing values in 'Label' column with the most frequent value: {mode_value}\")\n    train_data['Label'].fillna(mode_value, inplace=True)\n\nprint(\"\\nMissing Values in Validation Data:\")\nprint(val_data.isnull().sum())\n\nif val_data['Text'].isnull().sum() > 0:\n    print(\"\\nFilling missing values in 'Text' column with 'No Text'\")\n    val_data['Text'].fillna(\"No Text\", inplace=True)\n\n# For the Label column, fill with the most frequent value (mode)\nif val_data['Label'].isnull().sum() > 0:\n    mode_value = val_data['Label'].mode()[0]\n    print(f\"\\nFilling missing values in 'Label' column with the most frequent value: {mode_value}\")\n    val_data['Label'].fillna(mode_value, inplace=True)\n\nprint(\"\\nMissing Values in Test Data:\")\nprint(test_data.isnull().sum())\n\nif test_data['Text'].isnull().sum() > 0:\n    print(\"\\nFilling missing values in 'Text' column with 'No Text'\")\n    test_data['Text'].fillna(\"No Text\", inplace=True)\n\n\nprint(\"\\n Unique words of train dataset:\")\nprint(train_data.nunique())\n\nprint(\"\\n Unique words of validation dataset:\")\nprint(val_data.nunique())\n\nprint(\"\\n Unique words of test dataset:\")\nprint(test_data.nunique())\n\n# Create DataFrame with statistics for Label in Training and Validation datasets\nstats_df = pd.DataFrame({\n    \"Dataset\": [\"Training\", \"Validation\"],\n    \"Count\": [train_data['Label'].count(), val_data['Label'].count()],\n    \"Mean\": [train_data['Label'].mean(), val_data['Label'].mean()],\n    \"Std\": [train_data['Label'].std(), val_data['Label'].std()],\n    \"Min\": [train_data['Label'].min(), val_data['Label'].min()],\n    \"Max\": [train_data['Label'].max(), val_data['Label'].max()]\n})\n\n# Set figure size\nplt.figure(figsize=(8, 4))\n\n# Create heatmap for statistics visualization\nsns.heatmap(stats_df.set_index(\"Dataset\"), annot=True, cmap=\"Blues\", fmt=\".2f\", linewidths=0.5)\n# Add title\nplt.title(\"Statistical Overview of Labels in Training and Validation Datasets\")\n# Display plot\nplt.show()\n\n# Analysis of Label column (distribution of categories)\nprint(\"\\nLabel Distribution in Train Data:\")\nprint(train_data['Label'].value_counts())\n# Create plot for label distribution\nsns.countplot(x='Label', data=train_data)\nplt.title('Label Distribution in Train Data')\nplt.show()\n\n\nprint(\"\\nLabel Distribution in Validation Data:\")\nprint(val_data['Label'].value_counts())\nsns.countplot(x='Label', data=val_data)\nplt.title('Label Distribution in Validation Data')\nplt.show()\n\n# Text Analysis / Word Cloud Generation\ntext = ' '.join(train_data['Text'].tolist())  # Combine all texts into one string\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title('Word Cloud from Texts')\nplt.show()\n\n# Text cleaning and word splitting\nwords = ' '.join(train_data['Text']).lower()\nwords = re.findall(r'\\b\\w+\\b', words)  # Extract words\nword_freq = Counter(words).most_common(20)  # 20 most common words\n\n# Convert to Pandas DataFrame\nword_freq_df = pd.DataFrame(word_freq, columns=['Word', 'Frequency'])\n\n# Bar plot creation\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Frequency', y='Word', data=word_freq_df)\nplt.title('20 Most Common Words')\nplt.xlabel('Frequency')\nplt.ylabel('Words')\nplt.show()\n\n# Step 7: Handle outliers (only for numerical columns)\nif np.issubdtype(train_data['Label'].dtype, np.number):\n    Q1 = train_data['Label'].quantile(0.25)\n    Q3 = train_data['Label'].quantile(0.75)\n    IQR = Q3 - Q1\n    outliers = (train_data['Label'] < (Q1 - 1.5 * IQR)) | (train_data['Label'] > (Q3 + 1.5 * IQR))\n    print(\"\\nNumber of outliers in Label column:\", outliers.sum())\n\n    # Remove outliers (optional)\n    train_data = train_data[~outliers]\n\n\n# Text Length per Label (train dataset)\ntrain_data['Text_Length'] = train_data['Text'].apply(len)  # Calculate text length\nsns.boxplot(x='Label', y='Text_Length', data=train_data)\nplt.title('Text Length per Label')\nplt.show()\n\n# 1. Bigram Analysis (2-word combinations)\nvectorizer_bigrams = CountVectorizer(ngram_range=(2, 2))  # Create bigrams\nbigrams = vectorizer_bigrams.fit_transform(train_data['Text'])\nbigram_freq = zip(vectorizer_bigrams.get_feature_names_out(), bigrams.sum(axis=0).tolist()[0])\nbigram_freq = sorted(bigram_freq, key=lambda x: x[1], reverse=True)[:20]  # Top 20 most frequent bigrams\n\n# Convert to DataFrame\nbigram_df = pd.DataFrame(bigram_freq, columns=['Bigram', 'Frequency'])\n\n# Create a bar plot for bigrams\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Frequency', y='Bigram', data=bigram_df)\nplt.title('Top 20 Most Frequent Bigrams')\nplt.xlabel('Frequency')\nplt.ylabel('Bigrams')\nplt.show()\n\n# 2. Trigram Analysis (3-word combinations)\nvectorizer_trigrams = CountVectorizer(ngram_range=(3, 3))  # Create trigrams\ntrigrams = vectorizer_trigrams.fit_transform(train_data['Text'])\ntrigram_freq = zip(vectorizer_trigrams.get_feature_names_out(), trigrams.sum(axis=0).tolist()[0])\ntrigram_freq = sorted(trigram_freq, key=lambda x: x[1], reverse=True)[:20]  # Top 20 most frequent trigrams\n\n# Convert to DataFrame\ntrigram_df = pd.DataFrame(trigram_freq, columns=['Trigram', 'Frequency'])\n\n# Create a bar plot for trigrams\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Frequency', y='Trigram', data=trigram_df)\nplt.title('Top 20 Most Frequent Trigrams')\nplt.xlabel('Frequency')\nplt.ylabel('Trigrams')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:21:13.116116Z","iopub.execute_input":"2025-03-30T20:21:13.116500Z","iopub.status.idle":"2025-03-30T20:21:43.754404Z","shell.execute_reply.started":"2025-03-30T20:21:13.116472Z","shell.execute_reply":"2025-03-30T20:21:43.753276Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Defines text preprocessing function**","metadata":{}},{"cell_type":"code","source":"\n# lemmatizer = WordNetLemmatizer() # Initialize the stemmer\n# stemmer = PorterStemmer()\n# Initial stopwords list\n# stop_words = set(stopwords.words(\"english\"))\n# Remove negations from stopwords list\n# negation_words = {\"no\", \"nor\", \"not\", \"don't\", \"doesn't\", \"didn't\", \"won't\", \"wouldn't\", \"isn't\", \"wasn't\", \"aren't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\", \"can't\", \"couldn't\", \"shouldn't\", \"mustn't\", \"mightn't\"}\n# stop_words = stop_words - negation_words\n# custom_stopwords = {\"i\", \"to\", \"the\", \"a\", \"my\", \"and\", \"it\", \"you\", \"is\", \"for\", \"in\", \"s\", \"of\", \"t\", \"that\", \"on\", \"me\", \"so\", \"have\", \"m\"}\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nNEGATION_WORDS = {\"no\", \"not\", \"none\", \"neither\", \"nor\", \"never\"}\nNEGATION_PHRASES = {\n    \"not at all\": \"not_at_all\",\n    \"not only\": \"not_only\"\n}\n\ndef handle_negation(text):\n    \"\"\"Process negation in text by marking negated words\"\"\"\n    # Process phrases first\n    for phrase, replacement in NEGATION_PHRASES.items():\n        text = text.replace(phrase, replacement)\n    \n    words = word_tokenize(text.lower())\n    processed_words = []\n    negated = False\n    \n    for word in words:\n        if word in NEGATION_WORDS:\n            negated = True\n            processed_words.append(\"[NEG]\")  # Keep negation token\n        elif negated:\n            processed_words.append(f\"not_{word}\")\n            negated = False\n        else:\n            processed_words.append(word)\n    \n    return \" \".join(processed_words)\n\ndef replace_emoticons(text):\n    \"\"\"\n    Replaces common emoticons with text tokens preserving sentiment.\n    Improves accuracy by maintaining emotional context.\n    \"\"\"\n    # Emoticon-to-text mapping dictionary\n    EMOTICON_MAP = {\n        # Positive\n        \":â€‘)\": \" [happy] \", \":)\": \" [happy] \", \":-]\": \" [happy] \", \n        \":]\": \" [happy] \", \":-3\": \" [happy] \", \":3\": \" [happy] \",\n        \"=]\": \" [happy] \", \"=)\": \" [happy] \", \":)\": \" [happy] \",\n        \"=D\": \" [happy]\", '<3': ' [love] ', \n        \n        # Negative\n        \"=(\": \" [sad] \", \":(\": \" [sad] \", \":-c\": \" [sad] \",\n        \":-[\": \" [sad] \", \":[\": \" [sad] \", \":{\": \" [sad] \",\n    }\n    \n    # Replace emoticons\n    for emoticon, replacement in EMOTICON_MAP.items():\n        text = text.replace(emoticon, replacement)\n    \n    # Handle repeated characters (\"Heyyyy\" -> \"Heyy\")\n    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n    \n    # Clean whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text\n\ndef replace_social_sentiment(text):\n    \"\"\"\n    Replaces social media interjections with corresponding sentiment tokens.\n    Returns original text if no matches found.\n    \"\"\"\n    if not isinstance(text, str) or not text.strip():\n        return text  # Return original for non-text\n    \n    SOCIAL_PATTERNS = {\n        r\"\\bhahaha+\\b\": \"happy\",\n        r\"\\bhehe+\\b\": \"happy\",\n        r\"\\blol\\b\": \"happy\",\n        r\"\\blmao\\b\": \"happy\",\n        r\"\\bbruh+\\b\": \"awkward\",\n        r\"\\boof\\b\": \"awkward\",\n        r\"\\bwow\\b\": \"surprise\",\n        r\"\\bomg\\b\": \"surprise\",\n        r\"\\bugh\\b\": \"annoyed\",\n        r\"\\bsmh\\b\": \"disappointed\"\n    }\n\n    modified = False\n    new_text = text.lower()  # Work in lowercase for consistency\n\n    for pattern, replacement in SOCIAL_PATTERNS.items():\n        if re.search(pattern, new_text):\n            new_text = re.sub(pattern, replacement, new_text)\n            modified = True\n\n    return new_text if modified else text\n\ndef remove_unicode(text):\n    \"\"\"Convert to ASCII and clean special characters\"\"\"\n    text = text.encode('ascii', 'ignore').decode('ascii')\n    # Additional cleaning\n    text = re.sub(r\"[^\\w\\s.,!?;]\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\ndef preprocess_text(text):\n    \"\"\"Main text preprocessing pipeline\"\"\"\n    text = remove_unicode(text)\n    text = text.lower()   \n    text = replace_emoticons(text)\n    text = replace_social_sentiment(text)\n    # Remove mentions\n    text = re.sub(r\"@[\\w\\-_]+\", \"\", text)\n    # Remove numbers\n    text = re.sub(r'\\d+', '', text)\n    # Handle negation\n    text = handle_negation(text)\n    return text\n\n    # text = text.translate(str.maketrans('', '', string.punctuation)) \n    \n    # # Correct the spelling mistakes\n    # text = re.sub(r\"\\b(luv)\\b\", \"love\", text)            \n    # text = re.sub(r\"\\b(amzing)\\b\", \"amazing\", text)\n    # text = re.sub(r\"\\b(terible)\\b\", \"terrible\", text)\n    # text = re.sub(r\"\\b(excelent)\\b\", \"excellent\", text)\n    # text = re.sub(r\"\\b(perfonmence)\\b\", \"performance\", text)\n    # text = re.sub(r\"\\b(gud)\\b\", \"good\", text)\n    # text = re.sub(r\"\\b(vry)\\b\", \"very\", text)\n    # text = re.sub(r\"\\b(fanstic)\\b\", \"fantastic\", text)\n    # text = re.sub(r\"\\b(gr8)\\b\", \"great\", text)\n    # text = re.sub(r\"\\b(horrble)\\b\", \"horrible\", text)\n    # text = re.sub(r\"\\b(u)\\b\", \"you\", text)\n    # text = re.sub(r\"\\b(guyz)\\b\", \"guys\", text)\n    # text = re.sub(r\"\\b(knw)\\b\", \"know\", text)\n    # text = re.sub(r\"\\b(da)\\b\", \"the\", text)\n    # text = re.sub(r\"\\b(btw)\\b\", \"by the way\", text)\n    # text = re.sub(r\"\\b(r)\\b\", \"are\", text)\n    # text = re.sub(r\"\\b(cuz)\\b\", \"because\", text)\n    # text = re.sub(r\"\\b(tho)\\b\", \"though\", text)\n    # text = re.sub(r\"\\b(lol)\\b\", \"laugh out loud\", text)\n    # text = re.sub(r\"\\b(ur)\\b\", \"your\", text)\n\n\n    \n        # tokens = tweet_tokenizer.tokenize(text)  # Tokenization using TweetTokenizer\n\n    # return \" \".join(tokens)  # Return processed text as string\n\n    # #Tokenization\n    # words = word_tokenize(text)\n    # return \" \".join(words)\n\n    # Remove custom stopwords or \n    # Remove stopwords but keep negations\n    # words = [word for word in words if word not in stop_words]\n    # processed_text = ' '.join(words)\n    \n    # words = [word for word in words if word not in custom_stopwords]\n\n    # Lemmatization \n    # lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n    # processed_text = ' '.join(lemmatized_words)\n    # return processed_text\n\n    # tagged_words = pos_tag(words)\n    # # Keep only nouns (NN) and verbs (VB) //no\n    # filtered_words = [word for word, tag in tagged_words if tag.startswith('NN') or tag.startswith('VB')]\n    # # Rejoin words into text\n    # processed_text = ' '.join(filtered_words)\n    # return processed_text\n\n    # # Stemming\n    # stemmed_words = [stemmer.stem(word) for word in words] #probably not\n    # # Join words back into a single string\n    # processed_text = ' '.join(stemmed_words)\n    # return processed_text\n\n\n# def correct_spelling(text):\n#     blob = TextBlob(text)\n#     corrected_text = str(blob.correct())\n#     return corrected_text\n\n\n# Spelling correction\n# train_data['Text'] = train_data['Text'].apply(correct_spelling)\n# test_data['Text'] = test_data['Text'].apply(correct_spelling)\n# val_data['Text'] = val_data['Text'].apply(correct_spelling)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:22:30.977971Z","iopub.execute_input":"2025-03-30T20:22:30.978494Z","iopub.status.idle":"2025-03-30T20:22:31.923833Z","shell.execute_reply.started":"2025-03-30T20:22:30.978454Z","shell.execute_reply":"2025-03-30T20:22:31.922823Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Performs EDA after preprocessing**","metadata":{}},{"cell_type":"code","source":"def visualize_preprocessing_effects(original_texts, preprocessed_texts, sample_size=5):\n    \"\"\"\n    Compares original and preprocessed texts through multiple visualizations.\n    \"\"\"\n  \n    # Sample comparison - Show raw vs processed text examples\n    # This helps visually inspect what changes preprocessing introduced\n    df_comparison = pd.DataFrame({\n        'Original': original_texts[:sample_size],\n        'Processed': preprocessed_texts[:sample_size]\n    })\n    print(\"\\n--- Text samples before and after preprocessing ---\")\n    display(df_comparison)\n\n    # Text length comparison - Boxplot of word counts\n    # Shows if preprocessing significantly changes text length\n    plt.figure(figsize=(10, 5))\n    lengths = pd.DataFrame({\n        'Original': [len(text.split()) for text in original_texts],\n        'Processed': [len(text.split()) for text in preprocessed_texts]\n    })\n    sns.boxplot(data=lengths)\n    plt.title('Text Length Comparison (in words)')\n    plt.ylabel('Word Count')\n    plt.show()\n   \n    # Processed text word cloud\n    # Visualizes most prominent terms after preprocessing\n    text_processed = ' '.join(preprocessed_texts)\n    wordcloud = WordCloud(\n        width=800, \n        height=400, \n        background_color='white',\n        max_words=200  # Limits number of words shown for better readability\n    ).generate(text_processed)\n    \n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title('Processed Text Word Cloud')\n    plt.show()\n    \n    # Most frequent words analysis\n    # Extracts words (alphanumeric only), converts to lowercase and counts frequencies\n    words_processed = ' '.join(preprocessed_texts).lower()\n    words_processed = re.findall(r'\\b\\w+\\b', words_processed)  # \\b = word boundaries\n    word_freq_processed = Counter(words_processed).most_common(20)\n    \n    # Plot with proper pandas Series conversion to avoid warnings\n    plt.figure(figsize=(10, 6))\n    sns.barplot(\n        x=[freq for word, freq in word_freq_processed], \n        y=pd.Series([word for word, freq in word_freq_processed])\n    )\n    plt.title('Top 20 Most Frequent Words (Processed)')\n    plt.xlabel('Frequency')\n    plt.ylabel('Words')\n    plt.show()\n    \n    # Bigram analysis (2-word sequences)\n    # Important for understanding common phrases in the processed text\n    vectorizer_bigrams = CountVectorizer(\n        ngram_range=(2, 2),  # Only bigrams\n        token_pattern=r'\\b\\w+\\b',  # Same word tokenization as before\n        min_df=2  # Ignore bigrams appearing only once\n    )\n    \n    bigrams_processed = vectorizer_bigrams.fit_transform(preprocessed_texts)\n    bigram_features = vectorizer_bigrams.get_feature_names_out()\n    bigram_freqs = bigrams_processed.sum(axis=0).A1  # Convert to 1D array\n    top_bigrams = sorted(zip(bigram_features, bigram_freqs), \n                       key=lambda x: x[1], \n                       reverse=True)[:20]\n    \n    plt.figure(figsize=(10, 6))\n    sns.barplot(\n        x=[freq for bigram, freq in top_bigrams], \n        y=pd.Series([bigram for bigram, freq in top_bigrams])\n    )\n    plt.title('Top 20 Most Frequent Bigrams (Processed)')\n    plt.xlabel('Frequency')\n    plt.ylabel('Bigrams')\n    plt.tight_layout()  # Prevents label cutoff\n    plt.show()\n\n    # Trigram analysis (3-word sequences)\n    # Reveals longer patterns in the processed text\n    vectorizer_trigrams = CountVectorizer(\n        ngram_range=(3, 3),  # Only trigrams\n        token_pattern=r'\\b\\w+\\b',\n        min_df=2  # Minimum 2 occurrences\n    )\n    \n    trigrams_processed = vectorizer_trigrams.fit_transform(preprocessed_texts)\n    trigram_features = vectorizer_trigrams.get_feature_names_out()\n    trigram_freqs = trigrams_processed.sum(axis=0).A1\n    top_trigrams = sorted(zip(trigram_features, trigram_freqs),\n                        key=lambda x: x[1],\n                        reverse=True)[:20]\n    \n    plt.figure(figsize=(10, 6))\n    sns.barplot(\n        x=[freq for trigram, freq in top_trigrams],\n        y=pd.Series([trigram for trigram, freq in top_trigrams])\n    )\n    plt.title('Top 20 Most Frequent Trigrams (Processed)')\n    plt.xlabel('Frequency')\n    plt.ylabel('Trigrams')\n    plt.tight_layout()\n    plt.show()\n\n\nsample_texts = train_data['Text'].sample(1000, random_state=42).tolist()\nprocessed_samples = [preprocess_text(text) for text in sample_texts]\nvisualize_preprocessing_effects(sample_texts, processed_samples)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:22:47.739257Z","iopub.execute_input":"2025-03-30T20:22:47.739673Z","iopub.status.idle":"2025-03-30T20:22:50.594574Z","shell.execute_reply.started":"2025-03-30T20:22:47.739645Z","shell.execute_reply":"2025-03-30T20:22:50.593409Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Pipeline with TF-IDF and Logistic Regression for classification and evaluates model performance on validation test.**","metadata":{}},{"cell_type":"code","source":"text_preprocessor = FunctionTransformer(lambda docs: [preprocess_text(doc) for doc in docs])\n\nbest_model = Pipeline([\n    ('preprocessor', text_preprocessor),\n    ('tfidf', TfidfVectorizer(\n        min_df=8,\n        max_df=0.3,\n        ngram_range=(1, 3),\n        stop_words=None,\n        sublinear_tf=True\n    )),\n    ('model', LogisticRegression(\n        C=1.0,\n        penalty='l2',\n        solver='lbfgs',\n        max_iter=300,\n        multi_class='ovr',\n        random_state=42\n    ))\n])\n\n# Training and evaluation (Without GridSearch)\n# Fit the model on training data\nbest_model.fit(train_data['Text'], train_data['Label'])\n\n# Validation set evaluation\ny_val_pred = best_model.predict(val_data['Text'])\nprint(\"Validation Metrics:\")\nprint(\"------------------\")\nprint(f\"Accuracy: {accuracy_score(val_data['Label'], y_val_pred):.6f}\")\nprint(f\"Precision (Macro): {precision_score(val_data['Label'], y_val_pred, average='macro'):.4f}\")\nprint(f\"Recall (Macro): {recall_score(val_data['Label'], y_val_pred, average='macro'):.4f}\")\nprint(f\"F1-Score (Macro): {f1_score(val_data['Label'], y_val_pred, average='macro'):.4f}\")\n\n# Training set evaluation (to check for overfitting)\ny_train_pred = best_model.predict(train_data['Text'])\nprint(\"Train Metrics:\")\nprint(\"------------------\")\nprint(f\"Accuracy: {accuracy_score(train_data['Label'], y_train_pred):.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:22:59.799706Z","iopub.execute_input":"2025-03-30T20:22:59.800118Z","iopub.status.idle":"2025-03-30T20:24:46.679389Z","shell.execute_reply.started":"2025-03-30T20:22:59.800090Z","shell.execute_reply":"2025-03-30T20:24:46.678265Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Experiments with grid search in comments below**","metadata":{}},{"cell_type":"code","source":"# # Set random seed for reproducibility\n# np.random.seed(42)\n\n# # Initialize text preprocessor\n# text_preprocessor = FunctionTransformer(lambda docs: [preprocess_text(doc) for doc in docs])\n\n# # Define main processing pipeline\n# pipeline = Pipeline([\n#     ('preprocessor', text_preprocessor),  # Custom text preprocessing\n#     ('tfidf', TfidfVectorizer()),        # TF-IDF vectorization\n#     ('model', LogisticRegression(random_state=42))  # Classification model\n# ])\n\n\n# # Parameters for Grid Search optimization\n# param_grid = {\n#     # TF-IDF parameters\n#     'tfidf__min_df': [8],                # Minimum document frequency (ignore rare words)\n#     'tfidf__max_df': [0.3],              # Maximum document frequency (ignore common words)\n#     'tfidf__ngram_range': [(1,3)],       # Use unigrams, bigrams and trigrams\n#     'tfidf__stop_words': [None],         # No additional stopword removal\n#     'tfidf__sublinear_tf': [True],       # Apply sublinear TF scaling\n    \n#     # Logistic Regression parameters\n#     'model__C': [0.4],                   # Inverse regularization strength\n#     'model__penalty': ['l2'],            # L2 regularization\n#     'model__solver': ['saga'],           # Optimization algorithm\n#     'model__max_iter': [200],            # Maximum iterations\n#     'model__multi_class': ['multinomial'],  # Multiclass strategy\n#     'model__class_weight': [None]        # No class weighting\n# }\n\n# # Define evaluation metrics for Grid Search\n# scoring = {\n#     'accuracy': 'accuracy',\n#     'precision': 'precision_macro',\n#     'recall': 'recall_macro',\n#     'f1': 'f1_macro'\n# }\n\n# # Configure Grid Search with 5-fold cross-validation\n# grid_search = GridSearchCV(\n#     pipeline, \n#     param_grid, \n#     cv=5,                  # 5-fold cross-validation or 3 cross-validation (faster)\n#     scoring=scoring,       # Multiple evaluation metrics\n#     refit='accuracy',      # Refit best model on accuracy\n#     n_jobs=-1             # Use all available CPU cores\n# )\n\n# # Execute Grid Search\n# grid_search.fit(train_data['Text'], train_data['Label'])\n\n# # Retrieve and display results\n# results_df = pd.DataFrame(grid_search.cv_results_)\n# print(results_df[[\n#     'mean_test_accuracy', \n#     'mean_test_precision', \n#     'mean_test_recall', \n#     'mean_test_f1'\n# ]])\n\n# # Get best performing model\n# best_model = grid_search.best_estimator_\n\n# # Display training information\n# n_iterations = best_model.named_steps['model'].n_iter_\n# print(f\"Number of iterations completed: {n_iterations}\")\n\n# # Print best parameters and performance\n# print(f\"Best parameters: {grid_search.best_params_}\")\n# print(\"Best validation accuracy:\", grid_search.best_score_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T13:50:09.247478Z","iopub.execute_input":"2025-03-30T13:50:09.247813Z","iopub.status.idle":"2025-03-30T13:50:09.257524Z","shell.execute_reply.started":"2025-03-30T13:50:09.247788Z","shell.execute_reply":"2025-03-30T13:50:09.256403Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Learning Curve**","metadata":{}},{"cell_type":"code","source":"\n# Transform the data using the already trained Vectorizer\nX_transformed = best_model.named_steps['tfidf'].transform(train_data['Text'])\n\n# Learning Curve ONLY for the trained model (without re-running tfidf)\ntrain_sizes, train_scores, val_scores = learning_curve(\n    best_model.named_steps['model'], X_transformed, train_data['Label'], cv=2, scoring=\"accuracy\", \n    train_sizes=np.linspace(0.1, 1.0, 10)\n)\n# Calculate mean and standard deviation\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\nval_mean = np.mean(val_scores, axis=1)\nval_std = np.std(val_scores, axis=1)\n\n# Learning Curve plot\nplt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n\nplt.plot(train_sizes, val_mean, 'o-', color=\"b\", label=\"Cross-validation score\")\nplt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color=\"b\")\n\n# Add final metrics to the plot\ny_val_pred = best_model.predict(val_data['Text'])\nfinal_accuracy = accuracy_score(val_data['Label'], y_val_pred)\nplt.axhline(y=final_accuracy, color='green', linestyle='--', \n            label=f'Final Val Accuracy: {final_accuracy:.4f}')\n\nplt.xlabel(\"Training examples\")\nplt.ylabel(\"Score\")\nplt.legend(loc=\"best\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:25:39.165060Z","iopub.execute_input":"2025-03-30T20:25:39.165559Z","iopub.status.idle":"2025-03-30T20:26:17.003298Z","shell.execute_reply.started":"2025-03-30T20:25:39.165525Z","shell.execute_reply":"2025-03-30T20:26:17.002252Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **ROC curve**","metadata":{}},{"cell_type":"code","source":"\n# ROC Curve Plot\nplt.subplot(1, 2, 2)\n\n# Get predicted probabilities for validation set\nif hasattr(best_model.named_steps['model'], 'predict_proba'):\n    y_probs = best_model.predict_proba(val_data['Text'])[:, 1]\nelse:  # For models without predict_proba (like SVM), use decision function\n    y_scores = best_model.decision_function(val_data['Text'])\n    y_probs = (y_scores - y_scores.min()) / (y_scores.max() - y_scores.min())\n\n# Calculate ROC curve\nfpr, tpr, thresholds = roc_curve(val_data['Label'], y_probs)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.plot(fpr, tpr, color='darkorange', lw=2, \n         label=f'ROC curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:27:05.862117Z","iopub.execute_input":"2025-03-30T20:27:05.862637Z","iopub.status.idle":"2025-03-30T20:27:18.630563Z","shell.execute_reply.started":"2025-03-30T20:27:05.862601Z","shell.execute_reply":"2025-03-30T20:27:18.629310Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Generates submission file from test predictions and saves it as CSV**","metadata":{}},{"cell_type":"code","source":"test_predictions = best_model.predict(test_data['Text']) \nsubmission = pd.DataFrame({\n    'ID': test_data['ID'],\n    'Label': test_predictions\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created successfully!\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:27:23.985429Z","iopub.execute_input":"2025-03-30T20:27:23.985890Z","iopub.status.idle":"2025-03-30T20:27:30.308967Z","shell.execute_reply.started":"2025-03-30T20:27:23.985855Z","shell.execute_reply":"2025-03-30T20:27:30.307809Z"}},"outputs":[],"execution_count":null}]}